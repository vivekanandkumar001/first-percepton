# -*- coding: utf-8 -*-
"""Untitled-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x9iUAj2JeXo2Be-bDO9UX-4W9pO2qgh7
"""

from sklearn.datasets import make_classification
import numpy as np
x,y=make_classification(n_samples=100, n_features=2, n_informative=1, n_redundant=0, n_classes=2, n_clusters_per_class=1 , random_state=41, hypercube=False, class_sep=10)

import matplotlib.pyplot as plt

plt.figure(figsize=(10,6))
plt.scatter(x[:,0],x[:,1],c=y,cmap='winter',s=100)

def parameter(x,y):
    x=np.insert(x,0,1,axis=1)
    weights=np.ones(x.shape[1])
    lr=0.01

    for i in range(1000):
        j=np.random.randint(0,100)
        y_hat=step(np.dot(x[j],weights))
        weights=weights + lr*(y[j]-y_hat)*x[j]

    return weights[0],weights[1:]

def step(z):
    return 1 if z>=0 else 0

from sklearn.linear_model import Perceptron

intercept_,coef_=parameter(x,y)

print(intercept_)
print(coef_)

m= -(coef_[0]/coef_[1])
b= -(intercept_/coef_[1])

x_input=np.linspace(-3,3,100)
y_input=m*x_input+b

plt.figure(figsize=(10,6))
plt.scatter(x[:,0],x[:,1],c=y,cmap='winter',s=100)
plt.plot(x_input,y_input,color='red',linewidth=3)
plt.scatter(x[:,0],x[:,1],c=y,cmap='winter',s=100)
plt.ylim(-3,2)

def parameter(x,y):
  m=[]
  b=[]
  x=np.insert(x,0,1,axis=1)
  weights=np.ones(x.shape[1])
  lr=0.01
  for i in range(1000):
    j=np.random.randint(0,100)
    y_hat=step(np.dot(x[j],weights))
    weights=weights + lr*(y[j]-y_hat)*x[j]
    m.append(-weights[1]/weights[2])
    b.append(-weights[0]/weights[2])
  return m,b

m,b = parameter(x,y)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib notebook
from matplotlib.animation import FuncAnimation
import matplotlib.animation as animation

fig, ax = plt.subplots(figsize=(9,5))
x_i =np.arange(-3,3,0.1)
y_i = x_i * m[0]+b[0]
ax.scatter(x[:,0],x[:,1],c=y,cmap='winter',s=100)
line, = ax.plot(x_i, y_i,'-r', linewidth=2)
plt.ylim(-3,3)
def update(i):
  label='epoch {0}'.format(i+1)
  line.set_ydata(x_i*m[i]+b[i])
  ax.set_xlabel(label)

anim=FuncAnimation(fig,update,repeat=True, frames=1000, interval=100)

from IPython.display import HTML
HTML(anim.to_jshtml())

"""Let's train a Perceptron model using scikit-learn and compare its decision boundary."""

from sklearn.linear_model import Perceptron

# Train a Perceptron model from scikit-learn
perceptron_sklearn = Perceptron(random_state=41)
perceptron_sklearn.fit(x, y)

# Get the intercept and coefficients
intercept_sklearn = perceptron_sklearn.intercept_[0]
coef_sklearn = perceptron_sklearn.coef_[0]

print("Scikit-learn Perceptron Intercept:", intercept_sklearn)
print("Scikit-learn Perceptron Coefficients:", coef_sklearn)

# Plot the data and the scikit-learn perceptron decision boundary
plt.figure(figsize=(10, 6))
plt.scatter(x[:, 0], x[:, 1], c=y, cmap='winter', s=100)

# Calculate and plot the decision boundary line
x1_sklearn = np.linspace(-1, 5, 100)
# Equation of the decision boundary: w0*x1 + w1*x2 + intercept = 0
# Solving for x2: x2 = -(intercept + w0*x1) / w1
x2_sklearn = -(intercept_sklearn + x1_sklearn * coef_sklearn[0]) / coef_sklearn[1]

plt.plot(x1_sklearn, x2_sklearn, color='green', linestyle='--', label='Sklearn Perceptron Decision Boundary')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('Scikit-learn Perceptron Decision Boundary')
plt.legend()
plt.show()